
# **PHQ-9 ML Pipeline**

![Python](https://img.shields.io/badge/Python-3.11-blue)
![Pandas](https://img.shields.io/badge/Pandas-Data_Processing-yellow)
![SQL](https://img.shields.io/badge/SQL-Analytics-blueviolet)
![Spark](https://img.shields.io/badge/Apache_Spark-ML_Pipeline-orange)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-Linear_Regression-green)
![Data Engineering](https://img.shields.io/badge/Data_Engineering-End_to_End-red)

A complete end-to-end pipeline for analyzing student mentalâ€‘health indicators and predicting PHQâ€‘9 depression scores.  
The project demonstrates a **productionâ€‘style** workflow combining:

- Pandas ETL  
- SQL analytical layer  
- scikitâ€‘learn baseline model  
- Apache Spark ML pipeline  
- Clean modular architecture  

Part of the broader *Amygdata* research initiative.

---

# ğŸ§  **Project Summary**

```
Raw CSV â†’ Pandas ETL â†’ SQL Exploration â†’ ML (sklearn) â†’ Spark ML â†’ Artifacts
```

Shows the ability to move from raw data to scalable machineâ€‘learning pipelines.

---

# ğŸ“Š **Dataset Overview**

The dataset contains selfâ€‘reported mentalâ€‘health and lifestyle metrics from university students:

- PHQ-9 (depressive symptoms)
- GAD-7 (anxiety symptoms)
- SleepHours, ExerciseFreq, DietQuality
- AcademicStress, GPA
- Social & family support
- ScreenTime, OnlineStress  
- Binary mentalâ€‘health status label

Target variable:

```
PHQ9
```

Source file:

```
data/raw/mental_health.csv
```

---

# ğŸ—ï¸ **Architecture Diagram**

```
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Raw CSV Dataset    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                         Pandas (ETL Cleaning)
                                  â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Cleaned Dataset    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚             â”‚                â”‚
                    â–¼             â–¼                â–¼
           SQL Analytics     Pandas EDA      sklearn Model
         (sql/*.sql)       (01_eda.py)      (baseline LR)
                    â”‚                              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                     Spark Machine Learning Pipeline
                (Assembler â†’ Scaler â†’ LinearRegression)
                                  â”‚
                                  â–¼
                        Saved Model Artifacts (.model)
```

---

# ğŸ“‚ **Repository Structure**

```
PHQ-9 ML Pipeline
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ clean/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ train_linear_regression.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql
â”‚   â””â”€â”€ exploratory_queries.sql
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda_pandas.py
â”‚
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ phq9_lr_model/
â”‚
â””â”€â”€ README.md
```

---

# ğŸ§¬ **SQL Table Schema**

## **1ï¸âƒ£ RAW Table (staging)**

```sql
CREATE TABLE mental_health_raw (
    PHQ9 TEXT,
    GAD7 TEXT,
    SleepHours TEXT,
    ExerciseFreq TEXT,
    SocialActivity TEXT,
    OnlineStress TEXT,
    GPA TEXT,
    FamilySupport TEXT,
    ScreenTime TEXT,
    AcademicStress TEXT,
    DietQuality TEXT,
    SelfEfficacy TEXT,
    PeerRelationship TEXT,
    FinancialStress TEXT,
    SleepQuality TEXT,
    MentalHealthStatus TEXT
);
```

Purpose:

- easy ingestion from CSV  
- no strict types  
- mirrors raw data exactly  

---

## **2ï¸âƒ£ CLEAN Table (typed & analytical)**

```sql
CREATE TABLE mental_health_clean (
    id SERIAL PRIMARY KEY,
    PHQ9 DOUBLE PRECISION,
    GAD7 DOUBLE PRECISION,
    SleepHours DOUBLE PRECISION,
    ExerciseFreq DOUBLE PRECISION,
    SocialActivity DOUBLE PRECISION,
    OnlineStress DOUBLE PRECISION,
    GPA DOUBLE PRECISION,
    FamilySupport DOUBLE PRECISION,
    ScreenTime DOUBLE PRECISION,
    AcademicStress DOUBLE PRECISION,
    DietQuality DOUBLE PRECISION,
    SelfEfficacy DOUBLE PRECISION,
    PeerRelationship DOUBLE PRECISION,
    FinancialStress DOUBLE PRECISION,
    SleepQuality DOUBLE PRECISION,
    MentalHealthStatus INTEGER
);
```

Purpose:

- strong typing for ML  
- validated analytical dataset  
- consumed by both sklearn and Spark  

---

# ğŸ” **Pipeline Components**

## **1. Pandas Data Preprocessing**
- load raw CSV  
- cast to numeric types  
- drop missing values  
- save cleaned dataset â†’ `data/clean/`

## **2. EDA (notebook)**
- PHQâ€‘9 histogram  
- scatter (GADâ€‘7 vs PHQâ€‘9)  
- descriptive stats  
- feature distributions  

## **3. SQL Analytical Layer**
Queries include:

- PHQâ€‘9 & GADâ€‘7 descriptive statistics  
- correlations (`corr()`)  
- stressor analysis (Academic, Financial, Online)  
- GPA / SleepHours / ScreenTime buckets  
- top PHQâ€‘9 scorers  

## **4. sklearn Linear Regression**
Baseline predictive model using classic ML.

## **5. Spark ML Pipeline**
A scalable ML pipeline consisting of:

- `VectorAssembler`  
- `StandardScaler`  
- `LinearRegression`  
- `RegressionEvaluator`  

Model saved to:

```
artifacts/phq9_lr_model/
```

---

# ğŸ“ˆ **Model Performance**

## **Scikitâ€‘Learn Regression**
```
RMSE: ~4.7
RÂ²:    ~0.00
```

## **Spark ML Regression**
```
RMSE: ~4.75
RÂ²:    ~-0.08
```

Interpretation:

- PHQâ€‘9 is nonlinear and noisy  
- linear regression is intentionally simple  
- purpose is demonstrating full pipeline, not maximizing accuracy  

---

# â–¶ï¸ **How to Run the Project**

## **1. Create virtual environment**
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

## **2. Run data preprocessing & EDA**
```bash
python3 notebooks/01_eda_pandas.py
```

## **3. Run Spark training**
Requires **Java 17**

```bash
export JAVA_HOME=$(/usr/libexec/java_home -v 17)
python3 spark/train_linear_regression.py
```

---

# ğŸ§  **Key Takeaways**

- Complete endâ€‘toâ€‘end ML workflow  
- Strong separation of concerns (ETL â†’ SQL â†’ ML â†’ Spark)  
- Modular, productionâ€‘like repository  
- Clean reproducible pipelines  
- Integration of multiple tools used in modern data teams  

---

# ğŸ‘¤ **Author**

**RafaÅ‚ Bukowski**  
Project developed as part of the *Amygdata* research initiative.

